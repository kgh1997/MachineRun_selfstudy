{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블(Ensemble) 2 - AdaBoost, GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 학습 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 위한 사전 셋업\n",
    "grid_learn = [0.0001, 0.001, 0.01, 0.03, 0.05, 0.1, 0.2, 0.25, 0.5, 1.0]\n",
    "grid_n_estimator = [10, 50, 100, 300, 500]\n",
    "grid_ratio = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "grid_max_features = [0.3, 0.5, 0.7, 1.0]\n",
    "grid_max_depth = [1, 2, 4, 8]\n",
    "grid_min_samples_leaf = [1, 2, 3, 10, 100, 1500]\n",
    "grid_min_samples_split = [2, 4, 8, 16, 24, 30]\n",
    "grid_seed = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 부스팅:  GBM(Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래디언트 부스팅의 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "?GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost : 타이타닉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 df를 adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1043 entries, 0 to 1042\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  1043 non-null   int64  \n",
      " 1   Age       1043 non-null   float64\n",
      " 2   SibSp     1043 non-null   int64  \n",
      " 3   Parch     1043 non-null   int64  \n",
      " 4   Fare      1043 non-null   float64\n",
      " 5   Pclass_2  1043 non-null   int64  \n",
      " 6   Pclass_3  1043 non-null   int64  \n",
      " 7   Sex_1     1043 non-null   int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 65.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_titanic = pd.read_csv('C:/Users/gihun/Python_Data/data/df_titanic.csv')\n",
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_titanic.iloc[:,1:].values\n",
    "y = df_titanic['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86810551558753 0.8564593301435407\n"
     ]
    }
   ],
   "source": [
    "# Adaboost 모델 구축 및 학습, 평가\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dt = DecisionTreeClassifier(random_state=42,max_depth=1) # 성능이 약한 트리 먼저 생성\n",
    "ada_clf = AdaBoostClassifier(dt, n_estimators=200, algorithm='SAMME.R', learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "train_score = accuracy_score(y_train, ada_clf.predict(X_train))\n",
    "test_score = accuracy_score(y_test, ada_clf.predict(X_test))\n",
    "print(train_score,test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼 파라미터\n",
    "- 디폴트(default) 설정\n",
    "\n",
    "```python\n",
    "AdaBoostClassifier(\n",
    "    base_estimator=None,\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='SAMME.R',\n",
    "    random_state=None,\n",
    ")\n",
    "```\n",
    "- base_estimator: 예측할 모델, 디폴트는 DecisionTreeClassifier(max_depth=1)\n",
    "- n_estimators: 모형(week learner)의 갯수, 순차적으로 오류를 보정해서 수가 많으면 성능이 일정 수준까지 높아 질 수 있으나 수행 시간이 오래 걸린다는 단점이 있음. 디폴트는 50\n",
    "- learning_rate: 학습률, 0~1 사이의 값을 지정. 너무 작은 값인 경우 최소점을 찾아 예측 성능이 높지만 학습에 오래 걸리고 너무 큰 값인 경우 최소점을 찾지 못해 예측 성능이 떨어질 확률이 높음. 그래서 n_estimators와 상호 호환 필요. 디폴트는 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `AdaBoostClassifier` not found.\n"
     ]
    }
   ],
   "source": [
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost - GridSearchCV 를 활용한 최적의 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ※ GradientBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 동작원리\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "# 이렇게 세 개의 트리를 포함하는 앙상블을 구성\n",
    "# 앙상블 모델의 예측: 모든 트리의 예측을 더함\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) 그래디언트 부스팅 with 타이타닉 Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼 파라미터\n",
    "- 디폴트(default) 설정\n",
    "\n",
    "```python\n",
    "GradientBoostingClassifier(\n",
    "    loss='deviance',\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0,\n",
    "    criterion='friedman_mse',\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=3,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    init=None,\n",
    "    random_state=None,\n",
    "    max_features=None,\n",
    "    verbose=0,\n",
    "    max_leaf_nodes=None,\n",
    "    warm_start=False,\n",
    "    presort='auto',\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=None,\n",
    "    tol=0.0001,\n",
    ")\n",
    "```\n",
    "- loss: 손실 함수(loss function), 디폴트는 'deviance'\n",
    "- base_estimator: 예측할 모델, 디폴트는 DecisionTreeClassifier(max_depth=1)\n",
    "- n_estimators: 모형(week learner)의 갯수, 순차적으로 오류를 보정해서 수가 많으면 성능이 일정 수준까지 높아 질 수 있으나 수행 시간이 오래 걸린다는 단점이 있음. 디폴트는 100\n",
    "- learning_rate: 학습률, 0~1 사이의 값을 지정. 너무 작은 값인 경우 최소점을 찾아 예측 성능이 높지만 학습에 오래 걸리고 너무 큰 값인 경우 최소점을 찾지 못해 예측 성능이 떨어질 확률이 높음. 그래서 n_estimators와 상호 호환 필요. 디폴트는 0.1\n",
    "- min_samples_leaf: 말단 리프 노드의 최소한의 샘플 데이터 수, 디폴트 1\n",
    "- max_depth: 트리의 최대 깊이, 디폴트 3\n",
    "- subsample: n_estimator 모형(week learner)이 학습에 사용하는 데이터의 샘플링 비율, 디폴트 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost - GridSearchCV 를 활용한 최적의 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) 그래디언트 부스팅 with 사용자 행동 인식 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습] 와인데이터셋 - 그래디언트 부스팅 분류 -> 점수->튜닝-> 점수-> 피처 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습] 대출 상환 데이터를 이용하여 결정 트리, 랜덤 포레스트, 에이다부스트, 그래디언트 부스트 모델을 차례로 구축하고 성능을 평가하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3455c0890e7e2df1160e147aa3688f011a10f333e376754a307a9e8e4176ea7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
